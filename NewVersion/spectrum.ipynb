{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 环境准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ../input/dlib-whl/dlib-19.19.0-cp36-cp36m-linux_x86_64.whl\n",
    "!pip install ../input/sklearn/scikit_learn-0.22-cp36-cp36m-manylinux1_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import dlib\n",
    "import glob\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 变量声明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_video_path = \"/kaggle/input/deepfake-detection-challenge/test_videos/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 工具函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_faces(path_to_video,  save_dir=\".\", count=5):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    camera = cv2.VideoCapture(path_to_video)\n",
    "    path = Path(path_to_video)\n",
    "#     if not camera.isOpened():\n",
    "#         print(\"cannot open camera\")\n",
    "#         exit(0)\n",
    "    faces_count = 0\n",
    "    faces_path = []\n",
    "    while faces_count < count:\n",
    "        try:\n",
    "            ret, frame = camera.read()\n",
    "            frame_new = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            # 检测脸部\n",
    "            dets = detector(frame_new, 1)\n",
    "            # print(\"Number of faces detected: {}\".format(len(dets)))\n",
    "            if len(dets) > 0:\n",
    "                # 查找脸部位置\n",
    "                for i, face in enumerate(dets):\n",
    "                    #保存脸部图片,注意这里+ - 是根据dlib对脸部的定位来的，我这里选的50很适合我这个视频\n",
    "                    img1=frame[face.top()-50:face.bottom()+50,face.left()-50:face.right()+50]\n",
    "                    crop_size = (256,256)\n",
    "                    img1 = cv2.resize(img1, crop_size, interpolation = cv2.INTER_CUBIC)\n",
    "                    dst_path = f\"{save_dir}/{path.stem}_{faces_count:02}.jpg\"\n",
    "                    cv2.imwrite(dst_path, img1)\n",
    "                    faces_count += 1\n",
    "                    faces_path.append(dst_path)\n",
    "        except:\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "    return faces_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_faces(\"/kaggle/input/deepfake-detection-challenge/test_videos/ahjnxtiamx.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://www.astrobetter.com/blog/2010/03/03/fourier-transforms-of-images-in-python/\n",
    "\n",
    "def azimuthalAverage(image, center=None):\n",
    "    \"\"\"\n",
    "    Calculate the azimuthally averaged radial profile.\n",
    "\n",
    "    image - The 2D image\n",
    "    center - The [x,y] pixel coordinates used as the center. The default is \n",
    "             None, which then uses the center of the image (including \n",
    "             fracitonal pixels).\n",
    "    \n",
    "    \"\"\"\n",
    "    # Calculate the indices from the image\n",
    "    y, x = np.indices(image.shape)\n",
    "\n",
    "    if not center:\n",
    "        center = np.array([(x.max()-x.min())/2.0, (x.max()-x.min())/2.0])\n",
    "\n",
    "    r = np.hypot(x - center[0], y - center[1])\n",
    "\n",
    "    # Get sorted radii\n",
    "    ind = np.argsort(r.flat)\n",
    "    r_sorted = r.flat[ind]\n",
    "    i_sorted = image.flat[ind]\n",
    "\n",
    "    # Get the integer part of the radii (bin size = 1)\n",
    "    r_int = r_sorted.astype(int)\n",
    "\n",
    "    # Find all pixels that fall within each radial bin.\n",
    "    deltar = r_int[1:] - r_int[:-1]  # Assumes all radii represented\n",
    "    rind = np.where(deltar)[0]       # location of changed radius\n",
    "    nr = rind[1:] - rind[:-1]        # number of radius bin\n",
    "    \n",
    "    # Cumulative sum to figure out sums for each radius bin\n",
    "    csim = np.cumsum(i_sorted, dtype=float)\n",
    "    tbin = csim[rind[1:]] - csim[rind[:-1]]\n",
    "    radial_prof = tbin / nr\n",
    "\n",
    "    return radial_prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_psd1D(path_to_img, epsilon = 1e-8):\n",
    "    img = cv2.imread(path_to_img,0)\n",
    "    # Calculate FFT\n",
    "    f = np.fft.fft2(img)\n",
    "    fshift = np.fft.fftshift(f)\n",
    "    fshift += epsilon\n",
    "    magnitude_spectrum = 20*np.log(np.abs(fshift))\n",
    "    # Calculate the azimuthally averaged 1D power spectrum\n",
    "    psd1D = azimuthalAverage(magnitude_spectrum)\n",
    "    return psd1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#包导入\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_object(filename):\n",
    "    with open(filename, 'rb') as input:\n",
    "        return pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_object(\"../input/svm-model/svm.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd1D = get_psd1D(\"ahjnxtiamx_00.jpg\")\n",
    "model.predict(psd1D[:156].reshape(-1, 156))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['filename', 'label'])\n",
    "for i, video in enumerate(os.listdir(test_video_path)):\n",
    "    imgs = extract_faces(f\"{test_video_path}/{video}\")\n",
    "    print(imgs)\n",
    "    probas = []\n",
    "    for img in imgs:\n",
    "        psd1D_list = get_psd1D(img)\n",
    "        psd1D = psd1D[:156].reshape(-1, 156)\n",
    "        probas.append(model.predict(psd1D)[0])\n",
    "#         probas.append(model.predict_proba(psd1D))\n",
    "    proba = np.mean(probas)\n",
    "    print(proba)\n",
    "    df.loc[i] = [video, proba]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
